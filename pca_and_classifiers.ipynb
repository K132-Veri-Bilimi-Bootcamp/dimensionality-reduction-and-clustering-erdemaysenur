{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ÖDEV 1: PCA yardımı ile Classification,\n",
    "\n",
    "Bu ödevde \"Credit Risk Prediction\" veri setini kullanacağız. Amacımız, verinin boyut sayısını düşürerek olabildiğince yüksek accuracy değerini alabilmek. Aşağıda verinin okunma ve temizlenme kısmını hazırlayıp vereceğim. Devamında ise yapmanız gerekenler:\n",
    "\n",
    "1. PCA kullanarak verinin boyutunu düşürmek\n",
    "    * Önce explained varience ratio değerini inceleyerek veriyi kaç boyuta düşürebileceğini kontrol et.\n",
    "    * Daha sonra farklı boyutlarda denemeler yaparak boyutu düşürülmüş verileri elde et.\n",
    "2. Classification modellerini dene\n",
    "    * Logistic Regression\n",
    "    * Random Forest\n",
    "    * ve eğer istersen herhangi bir modelle daha\n",
    "\n",
    "İsteğe bağlı olarak, verinin boyutunu düşürmek için diğer yöntemleri de kullanıp en yüksek accuracy değerini almayı deneyebilirsin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df: pd.DataFrame = pd.read_csv('./credit_risk_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person_age                       0\n",
      "person_income                    0\n",
      "person_home_ownership            0\n",
      "person_emp_length              895\n",
      "loan_intent                      0\n",
      "loan_grade                       0\n",
      "loan_amnt                        0\n",
      "loan_int_rate                 3116\n",
      "loan_status                      0\n",
      "loan_percent_income              0\n",
      "cb_person_default_on_file        0\n",
      "cb_person_cred_hist_length       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Null değerleri sütun ortalaması ile dolduruyoruz\n",
    "df[\"person_emp_length\"].fillna(df[\"person_emp_length\"].median(), inplace=True)\n",
    "df[\"loan_int_rate\"].fillna(df[\"loan_int_rate\"].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>person_age</th>\n",
       "      <td>32416.0</td>\n",
       "      <td>27.747008</td>\n",
       "      <td>6.354100</td>\n",
       "      <td>20.00</td>\n",
       "      <td>23.00</td>\n",
       "      <td>26.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>144.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_income</th>\n",
       "      <td>32416.0</td>\n",
       "      <td>66091.640826</td>\n",
       "      <td>62015.580269</td>\n",
       "      <td>4000.00</td>\n",
       "      <td>38542.00</td>\n",
       "      <td>55000.00</td>\n",
       "      <td>79218.00</td>\n",
       "      <td>6000000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person_emp_length</th>\n",
       "      <td>32416.0</td>\n",
       "      <td>4.768880</td>\n",
       "      <td>4.090411</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>7.00</td>\n",
       "      <td>123.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_amnt</th>\n",
       "      <td>32416.0</td>\n",
       "      <td>9593.845632</td>\n",
       "      <td>6322.730241</td>\n",
       "      <td>500.00</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>8000.00</td>\n",
       "      <td>12250.00</td>\n",
       "      <td>35000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_int_rate</th>\n",
       "      <td>32416.0</td>\n",
       "      <td>11.014662</td>\n",
       "      <td>3.083050</td>\n",
       "      <td>5.42</td>\n",
       "      <td>8.49</td>\n",
       "      <td>10.99</td>\n",
       "      <td>13.11</td>\n",
       "      <td>23.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_status</th>\n",
       "      <td>32416.0</td>\n",
       "      <td>0.218688</td>\n",
       "      <td>0.413363</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loan_percent_income</th>\n",
       "      <td>32416.0</td>\n",
       "      <td>0.170250</td>\n",
       "      <td>0.106812</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <td>32416.0</td>\n",
       "      <td>5.811297</td>\n",
       "      <td>4.059030</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              count          mean           std      min  \\\n",
       "person_age                  32416.0     27.747008      6.354100    20.00   \n",
       "person_income               32416.0  66091.640826  62015.580269  4000.00   \n",
       "person_emp_length           32416.0      4.768880      4.090411     0.00   \n",
       "loan_amnt                   32416.0   9593.845632   6322.730241   500.00   \n",
       "loan_int_rate               32416.0     11.014662      3.083050     5.42   \n",
       "loan_status                 32416.0      0.218688      0.413363     0.00   \n",
       "loan_percent_income         32416.0      0.170250      0.106812     0.00   \n",
       "cb_person_cred_hist_length  32416.0      5.811297      4.059030     2.00   \n",
       "\n",
       "                                 25%       50%       75%         max  \n",
       "person_age                     23.00     26.00     30.00      144.00  \n",
       "person_income               38542.00  55000.00  79218.00  6000000.00  \n",
       "person_emp_length               2.00      4.00      7.00      123.00  \n",
       "loan_amnt                    5000.00   8000.00  12250.00    35000.00  \n",
       "loan_int_rate                   8.49     10.99     13.11       23.22  \n",
       "loan_status                     0.00      0.00      0.00        1.00  \n",
       "loan_percent_income             0.09      0.15      0.23        0.83  \n",
       "cb_person_cred_hist_length      3.00      4.00      8.00       30.00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Outlier temizliği\n",
    "df = df[df['person_age']<=100]\n",
    "df = df[df['person_emp_length'] <= 60]\n",
    "df = df[df['person_income']<=4e6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['person_home_ownership', 'loan_intent', 'loan_grade',\n",
       "       'cb_person_default_on_file'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kategorik verileri alıyoruz ve one hot encoding haline getiriyoruz\n",
    "cat_cols = pd.DataFrame(df[df.select_dtypes(include=['object']).columns])\n",
    "cat_cols.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "encoded_cat_cols = pd.get_dummies(cat_cols)\n",
    "df.drop(df.select_dtypes(include=['object']).columns, axis=1,inplace=True)\n",
    "df = pd.concat([df,encoded_cat_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop('loan_status', axis=1).values\n",
    "y = df['loan_status'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(1, test_size=0.1)\n",
    "train_idx, test_idx = next(split.split(X, y))\n",
    "train_x = X[train_idx]\n",
    "test_x = X[test_idx]\n",
    "\n",
    "train_y = y[train_idx]\n",
    "test_y = y[test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PCA (Principal Component Analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA, popüler bir boyut azaltma yöntemidir. Temel olarak bir projeksiyon işlemi yapar; ilk olarak veriye en uygun uzayı tanımlar ve istenen boyuta indirgemek için temel bileşenleri kullanarak veriyi alt boyuta yansıtır.\n",
    "\n",
    "Temel bileşenler, SVD (Singular Value Decomposition) adı verilen bir matris çarpımından elde edilir. Veri, 3 matrisin çarpımı şeklinde ifade edilir ve bu matrislerden biri temel bileşenleri içeren V matrisinin transpozudur. Düşürülmek istenen boyut kadar temel bileşeni içeren matrisle veri çarpılır, bu şekilde yeni veri elde edilir.\n",
    "\n",
    "**PCA, bir orijin etrafında dağılmış şekilde olan veriye uygulanır, veri bu halde değilse bu hale getirilmedilir. Sklearn PCA sınıfı bu işlemi otomatik yapar.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_train_2d = pca.fit_transform(train_x)\n",
    "X_test_2d = pca.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.63902202e-05, -9.00534957e-06],\n",
       "       [ 9.99267509e-01,  3.82680580e-02],\n",
       "       [ 1.19151653e-05, -4.37782299e-05],\n",
       "       [ 3.82680574e-02, -9.99267506e-01],\n",
       "       [-9.83842189e-08, -7.47661530e-05],\n",
       "       [-5.88426323e-07, -1.25056071e-05],\n",
       "       [ 9.29050695e-06, -3.08326839e-06],\n",
       "       [ 2.19633578e-06, -4.92195564e-06],\n",
       "       [ 1.25914405e-08, -4.97205338e-08],\n",
       "       [-2.25842169e-07,  4.99321667e-07],\n",
       "       [-1.98308505e-06,  4.47235450e-06],\n",
       "       [ 3.68964170e-08,  1.90973272e-07],\n",
       "       [-1.25359915e-07,  3.96658192e-07],\n",
       "       [ 3.13750202e-07, -1.54133366e-06],\n",
       "       [-3.18772434e-07,  5.63387055e-07],\n",
       "       [ 4.74983886e-08,  9.06117341e-08],\n",
       "       [ 4.59873404e-08,  2.99703405e-07],\n",
       "       [ 7.01561027e-08,  9.62740416e-06],\n",
       "       [ 8.34773453e-08, -3.18260241e-06],\n",
       "       [-1.54275283e-07,  1.77469101e-06],\n",
       "       [-9.87241709e-08, -4.20600797e-06],\n",
       "       [ 6.42868084e-08, -2.55887540e-06],\n",
       "       [ 2.68023481e-08, -1.04654621e-06],\n",
       "       [ 8.27684916e-09, -4.08063179e-07],\n",
       "       [ 4.32132374e-08,  2.69921778e-06],\n",
       "       [-4.32132374e-08, -2.69921778e-06]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98722002, 0.01277995])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İlk component verinin varyansının 98%'sini içeriyormuş."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Accuracy:  83.64702252391237 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "\n",
    "gbc = GradientBoostingClassifier(max_depth=2, min_samples_split=3, n_estimators=150)\n",
    "gbc.fit(X_train_2d, train_y)\n",
    "\n",
    "errors = [mean_squared_error(test_y, y_pred) for y_pred in gbc.staged_predict(X_test_2d)]\n",
    "acc = [accuracy_score(test_y, y_pred) for y_pred in gbc.staged_predict(X_test_2d)]\n",
    "best_n_estimators = np.argmax(acc)\n",
    "\n",
    "gbc = GradientBoostingClassifier(max_depth=3, n_estimators=best_n_estimators)\n",
    "gbc.fit(X_train_2d,train_y)\n",
    "y_pred = gbc.predict(X_test_2d)\n",
    "accuracy_gbc = accuracy_score(test_y, y_pred)*100\n",
    "\n",
    "print(\"Gradient Boosting Classifier Accuracy: \",accuracy_gbc,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranfom Forests accuracy on test set:  83.52360382597963 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=60, bootstrap=True)\n",
    "rfc.fit(X_train_2d, train_y)\n",
    "y_pred = rfc.predict(X_test_2d)\n",
    "accuracy_rfc = accuracy_score(test_y, y_pred)*100\n",
    "print(\"Ranfom Forests accuracy on test set: \",accuracy_rfc,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 6         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35\n",
      "Trainable params: 35\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_nn = scaler.fit_transform(X_train_2d)\n",
    "X_test_nn = scaler.transform(X_test_2d)\n",
    "\n",
    "input_size = X_train_nn.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=input_size, input_dim=X_train_nn.shape[1], activation=\"relu\"))\n",
    "model.add(Dense(units=input_size, activation=\"relu\"))\n",
    "model.add(Dense(units=input_size, activation=\"relu\"))\n",
    "model.add(Dense(units=input_size, activation=\"relu\"))\n",
    "model.add(Dense(units=input_size, activation=\"relu\"))\n",
    "model.add(Dense(units=input_size/2, activation=\"relu\"))\n",
    "model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'] )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_nn, train_y, epochs=100, verbose=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set:  77.52828001976013 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on validation set: \",history.history[\"val_accuracy\"][-1]*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7812\n",
      "\n",
      "Accuracy on test set:  78.12403440475464 %\n"
     ]
    }
   ],
   "source": [
    "y_pred_nn = model.predict(X_test_nn)\n",
    "accuracy = np.dot(history.history[\"accuracy\"],100)\n",
    "loss = history.history['loss']\n",
    "\n",
    "score = model.evaluate(X_test_nn, test_y, steps=5)\n",
    "accuracy_nn = score[1]*100\n",
    "print()\n",
    "print(\"Accuracy on test set: \",accuracy_nn,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy on test set:  81.57975933353903 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = SVC(kernel=\"rbf\")\n",
    "svc.fit(X_train_2d, train_y)\n",
    "y_pred = svc.predict(X_test_2d)\n",
    "accuracy_svc = accuracy_score(test_y, y_pred)*100\n",
    "print(\"SVC Accuracy on test set: \",accuracy_svc,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forests</th>\n",
       "      <td>83.523604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting Classifier</th>\n",
       "      <td>83.647023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Network</th>\n",
       "      <td>78.124034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Classifier</th>\n",
       "      <td>81.579759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Accuracy\n",
       "Random Forests                83.523604\n",
       "Gradient Boosting Classifier  83.647023\n",
       "Neural Network                78.124034\n",
       "Support Vector Classifier     81.579759"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare = pd.DataFrame(index=[\"Random Forests\",\"Gradient Boosting Classifier\",\"Neural Network\",\"Support Vector Classifier\"],\n",
    "                       columns=[\"Accuracy\"],\n",
    "                      data=[accuracy_rfc,accuracy_gbc,accuracy_nn,accuracy_svc])\n",
    "compare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
